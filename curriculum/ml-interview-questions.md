# AI/ML Interview Questions by Category

## Month 1: Foundations

### Week 1: Text Classification Pipeline
1. What's the difference between supervised, unsupervised, and reinforcement learning?
2. How do you handle missing data?
3. What are precision, recall, and F1-score?
4. Explain ROC curves and AUC.
5. What is tokenization?
6. Explain word embeddings.
7. What is the difference between count vectorization and TF-IDF?
8. How do you handle imbalanced datasets?
9. What is cross-validation and why it's important?
10. How do you choose the right evaluation metric for your problem?

### Week 2: Deep Learning Basics
1. What are convolution operations?
2. Explain pooling layers and their types.
3. What is data augmentation in CV?
4. How does transfer learning work?
5. What is the role of stride in CNNs?
6. Explain the basic architecture of a neural network.
7. What are activation functions and why are they needed?
8. How does backpropagation work?
9. What is gradient descent? Compare its variants.
10. What is batch normalization and why is it useful?

### Week 3: Recommender Systems
1. What is collaborative filtering?
2. Explain content-based vs collaborative filtering.
3. How do you handle cold start problems?
4. What is matrix factorization?
5. How do you evaluate recommender systems?
6. What is the role of user embeddings?
7. How do you handle scalability in recommender systems?
8. Explain different similarity metrics.
9. What is explicit vs implicit feedback?
10. How do you handle temporal aspects in recommendations?

### Week 4: Reinforcement Learning Basics
1. What is the difference between policy and value learning?
2. Explain the exploration-exploitation tradeoff.
3. What is Q-learning?
4. How does policy gradient work?
5. What is the role of reward shaping?
6. Explain the credit assignment problem.
7. What is temporal difference learning?
8. How do you handle continuous action spaces?
9. What is the difference between on-policy and off-policy learning?
10. How does Monte Carlo tree search work?

## Month 2: Advanced Techniques

### Week 5-6: Advanced NLP & Transformers
1. How does BERT work?
2. What is masked language modeling?
3. Explain the differences between GPT and BERT architectures.
4. What is beam search?
5. How does sequence-to-sequence modeling work?
6. What are attention masks?
7. How do you handle long documents in transformers?
8. What is the role of layer normalization in transformers?
9. Explain different approaches to named entity recognition.
10. How do transformers handle positional information?

### Week 7-8: Production ML & Vector Search
1. What is a vector database and how does it differ from traditional databases?
2. Explain the concept of vector similarity search.
3. What are the common distance metrics used in vector search?
4. What is Retrieval-Augmented Generation?
5. How do you choose appropriate chunks for document indexing?
6. Explain different retrieval strategies in RAG.
7. How do you handle context window limitations?
8. What are the challenges in maintaining relevance in RAG?
9. How do you evaluate RAG system performance?
10. Explain different reranking strategies.

## Month 3: Integration & Mastery

### Week 9-10: Large Language Models
1. How do large language models work?
2. Explain the scaling laws in language models.
3. What are the key differences between decoder-only and encoder-decoder models?
4. How do you handle prompt engineering?
5. What is few-shot and zero-shot learning?
6. How do you evaluate language model performance?
7. What are the challenges in language model deployment?
8. Explain different model compression techniques.
9. How do you handle bias in language models?
10. What are the latest developments in LLM architecture?

### Week 11-12: AI Agents & System Integration
1. What defines an AI agent?
2. How do multiple agents coordinate?
3. Explain agent communication protocols.
4. What are the challenges in multi-agent learning?
5. How do you handle conflicting agent goals?
6. What is the role of memory in AI agents?
7. How do agents handle tool selection?
8. What are the security considerations in multi-agent systems?
9. How do you debug multi-agent systems?
10. Explain agent specialization and division of labor.

## General Topics (Relevant Throughout)

### Mathematics and Statistics
1. Explain Bayes' theorem and its applications in ML.
2. What is maximum likelihood estimation?
3. Explain the central limit theorem.
4. What is hypothesis testing?
5. Explain different probability distributions.
6. What is the role of matrices in deep learning?
7. Explain eigenvalues and eigenvectors.
8. What is singular value decomposition?
9. Explain the chain rule in backpropagation.
10. What is the role of calculus in optimization?

### MLOps and System Design
1. How do you handle model versioning?
2. Explain A/B testing for ML models.
3. What is CI/CD for ML?
4. How do you detect model drift?
5. Explain model serving architectures.
6. What are the components of an ML pipeline?
7. How do you handle model fallbacks?
8. What is the role of caching in ML systems?
9. How do you scale vector similarity search?
10. Explain strategies for model updates in production.

### Ethics and Practical Considerations
1. How do you detect and mitigate bias in ML models?
2. What is model interpretability?
3. Explain fairness metrics in ML.
4. What is differential privacy?
5. How do you handle sensitive data in ML pipelines?
6. How do you measure ROI for ML projects?
7. When should you not use ML?
8. How do you prioritize ML projects?
9. What are the costs involved in ML deployment?
10. How do you handle technical debt in ML systems?

Note: These questions are aligned with the project timeline and will be covered through hands-on implementation. Each project will help you understand and be able to answer several of these questions from practical experience.